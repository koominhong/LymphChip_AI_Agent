import streamlit as st
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.preprocessing import StandardScaler
from scipy.signal import savgol_filter
from scipy.interpolate import interp1d
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams['font.family'] = 'AppleGothic'  # Mac
# matplotlib.rcParams['font.family'] = 'Malgun Gothic'  # Windows
matplotlib.rcParams['axes.unicode_minus'] = False
import warnings
warnings.filterwarnings('ignore')

st.set_page_config(page_title="ë¯¸ì„¸ìƒë¦¬ìœ ì²´ì¹© ì•½ë¬¼ ë™íƒœ ë¶„ì„", page_icon="ğŸ§¬", layout="wide")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False
if 'xgb_models' not in st.session_state:
    st.session_state.xgb_models = {}
if 'scaler_X' not in st.session_state:
    st.session_state.scaler_X = None
if 'scaler_y' not in st.session_state:
    st.session_state.scaler_y = {}
if 'default_values' not in st.session_state:
    st.session_state.default_values = None
if 'feature_names' not in st.session_state:
    st.session_state.feature_names = ['Lp_ve', 'K', 'P_oncotic', 'sigma_ve', 'D_gel']
if 'target_names' not in st.session_state:
    # ğŸ”¥ ì˜¬ë°”ë¥¸ ìˆœì„œ: Decayê°€ ECMë³´ë‹¤ ë¨¼ì €!
    st.session_state.target_names = ['Total mass', 'Lymph', 'Blood', 'Decay', 'ECM']
if 'hyperparams' not in st.session_state:
    st.session_state.hyperparams = {
        'n_estimators': 100,
        'max_depth': 6,
        'learning_rate': 0.1,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'min_child_weight': 1
    }
if 'smoothing_params' not in st.session_state:
    st.session_state.smoothing_params = {
        'enabled': True,
        'method': 'savgol',
        'window_length': 11,
        'poly_order': 3,
        'spline_kind': 'cubic'
    }

# ì œì™¸í•  ì‹œíŠ¸ ëª©ë¡
EXCLUDE_SHEETS = ['Summary', 'step size', 'Sheet9']

def extract_input_variables_type1(df):
    """Type 1 íŒŒì¼: AFì—´(31), AHì—´(33)ì˜ 3~7í–‰"""
    try:
        if df.shape[1] < 34:
            return None
        
        input_vars = {}
        for row_idx in range(2, 7):
            var_name = str(df.iloc[row_idx, 31]).strip()
            var_value_str = str(df.iloc[row_idx, 33])
            
            try:
                var_value_clean = var_value_str.split()[0]
                var_value = float(var_value_clean)
                input_vars[var_name] = var_value
                st.success(f"  âœ… {var_name} = {var_value:.2e}")
            except:
                st.warning(f"  âš ï¸ {var_name}: '{var_value_str}' ë³€í™˜ ì‹¤íŒ¨")
        
        return input_vars if input_vars else None
    except Exception as e:
        st.error(f"  âŒ ì…ë ¥ ë³€ìˆ˜ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
        return None

def extract_target_variables_type1(df):
    """Type 1 íŒŒì¼: O~Tì—´(14~19), Time â‰¤ 72
    ì˜¬ë°”ë¥¸ ìˆœì„œ: Time, Total mass, Lymph, Blood, Decay, ECM
    """
    try:
        if df.shape[1] < 20:
            return None
        
        # 1í–‰ë¶€í„° ì½ê¸° (0í–‰ì€ í—¤ë”)
        target_df = df.iloc[1:, 14:20].copy()
        
        # ğŸ”¥ ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ì»¬ëŸ¼ëª… ì§€ì •!
        target_df.columns = ['Time(h)', 'Total mass', 'Lymph', 'Blood', 'Decay', 'ECM']
        
        for col in target_df.columns:
            target_df[col] = pd.to_numeric(target_df[col], errors='coerce')
        
        target_df = target_df.dropna()
        
        if 'Time(h)' in target_df.columns:
            original_len = len(target_df)
            target_df = target_df[target_df['Time(h)'] <= 72].reset_index(drop=True)
            st.info(f"  ğŸ” Time í•„í„°ë§: {original_len}ê°œ â†’ {len(target_df)}ê°œ")
        
        return target_df if len(target_df) > 0 else None
    except Exception as e:
        st.error(f"  âŒ íƒ€ê²Ÿ ë³€ìˆ˜ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
        return None

def detect_file_type(df):
    """íŒŒì¼ íƒ€ì… ìë™ ê°ì§€"""
    if df.shape[1] >= 34:
        if any('lp_ve' in str(df.iloc[i, 31]).lower() for i in range(min(10, df.shape[0]))):
            return "TYPE1"
    return "TYPE2"

def load_and_process_files(uploaded_files):
    """íŒŒì¼ ì²˜ë¦¬ - Timeì„ ì…ë ¥ ë³€ìˆ˜ë¡œ í¬í•¨"""
    all_X = []
    all_y = []
    total_sheets_processed = 0
    
    for file_idx, uploaded_file in enumerate(uploaded_files):
        try:
            st.markdown(f"## ğŸ“„ íŒŒì¼ {file_idx + 1}: {uploaded_file.name}")
            
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file, header=None)
                sheets_to_process = [('default', df)]
            else:
                xl = pd.ExcelFile(uploaded_file)
                st.info(f"ğŸ“‘ ì´ {len(xl.sheet_names)}ê°œ ì‹œíŠ¸ ë°œê²¬")
                
                valid_sheets = [s for s in xl.sheet_names if s not in EXCLUDE_SHEETS]
                excluded_count = len(xl.sheet_names) - len(valid_sheets)
                
                if excluded_count > 0:
                    excluded = [s for s in xl.sheet_names if s in EXCLUDE_SHEETS]
                    st.warning(f"â­ï¸ {excluded_count}ê°œ ì‹œíŠ¸ ì œì™¸: {', '.join(excluded)}")
                
                st.success(f"âœ… {len(valid_sheets)}ê°œ ì‹œíŠ¸ ì²˜ë¦¬ ì˜ˆì •")
                
                sheets_to_process = [(sheet_name, pd.read_excel(uploaded_file, sheet_name=sheet_name, header=None)) 
                                     for sheet_name in valid_sheets]
            
            for sheet_name, df in sheets_to_process:
                with st.expander(f"ğŸ“Š ì‹œíŠ¸: {sheet_name}", expanded=False):
                    st.info(f"ğŸ“ í¬ê¸°: {df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´")
                    
                    file_type = detect_file_type(df)
                    st.info(f"ğŸ” íƒ€ì…: {file_type}")
                    
                    if file_type == "TYPE1":
                        input_vars = extract_input_variables_type1(df)
                        if not input_vars:
                            st.error(f"  âš ï¸ ì…ë ¥ ë³€ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨ - ê±´ë„ˆëœ€")
                            continue
                        
                        target_df = extract_target_variables_type1(df)
                        if target_df is None:
                            st.error(f"  âš ï¸ íƒ€ê²Ÿ ë³€ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨ - ê±´ë„ˆëœ€")
                            continue
                    
                    elif file_type == "TYPE2":
                        st.warning("  âš ï¸ TYPE2 íŒŒì¼ í˜•ì‹ - ê±´ë„ˆëœ€")
                        continue
                    
                    # Case 1 ê¸°ë³¸ê°’ ì„¤ì •
                    if 'case 1' in sheet_name.lower():
                        st.session_state.default_values = input_vars.copy()
                        st.success(f"  âœ…âœ… Case 1 ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •ë¨!")
                        for k, v in input_vars.items():
                            st.info(f"    {k} = {v:.2e}")
                    
                    # X ë°ì´í„° ìƒì„±: [ì•½ë¬¼ ë³€ìˆ˜ 5ê°œ + Time]
                    base_X = [input_vars.get(feat, 0.0) for feat in st.session_state.feature_names]
                    
                    samples_added = 0
                    for idx, row in target_df.iterrows():
                        # Timeì„ ì…ë ¥ ë³€ìˆ˜ì— ì¶”ê°€
                        X_sample = base_X + [row['Time(h)']]
                        
                        # ğŸ”¥ ì˜¬ë°”ë¥¸ ìˆœì„œ: Total mass, Lymph, Blood, Decay, ECM
                        y_sample = [row['Total mass'], row['Lymph'], row['Blood'], 
                                   row['Decay'], row['ECM']]
                        
                        all_X.append(X_sample)
                        all_y.append(y_sample)
                        samples_added += 1
                    
                    st.success(f"  âœ… {samples_added}ê°œ ìƒ˜í”Œ ì¶”ê°€ë¨")
                    total_sheets_processed += 1
            
            st.success(f"âœ… {uploaded_file.name} ì™„ë£Œ")
            
        except Exception as e:
            st.error(f"âŒ {uploaded_file.name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            import traceback
            st.error(traceback.format_exc())
            continue
    
    if len(all_X) == 0:
        st.error("âŒ ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    
    X = np.array(all_X)
    y = np.array(all_y)
    
    st.success(f"ğŸ‰ ì´ {total_sheets_processed}ê°œ ì‹œíŠ¸ì—ì„œ {len(X)}ê°œ ìƒ˜í”Œ ìƒì„± ì™„ë£Œ!")
    st.info(f"ğŸ“Š ë°ì´í„°ì…‹ í˜•íƒœ: X={X.shape}, y={y.shape}")
    st.info(f"ğŸ“¥ ì…ë ¥ ë³€ìˆ˜: ì•½ë¬¼ 5ê°œ + Time = 6ê°œ")
    st.info(f"ğŸ“¤ íƒ€ê²Ÿ ë³€ìˆ˜: {', '.join(st.session_state.target_names)}")
    st.info(f"â° Time ë²”ìœ„: {X[:, -1].min():.2f}h ~ {X[:, -1].max():.2f}h")
    
    return X, y

def train_xgboost_models(X, y, hyperparams):
    """XGBoost ëª¨ë¸ í•™ìŠµ - ê° íƒ€ê²Ÿ ë³€ìˆ˜ë³„ ë…ë¦½ ëª¨ë¸"""
    st.session_state.scaler_X = StandardScaler()
    X_scaled = st.session_state.scaler_X.fit_transform(X)
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, target_name in enumerate(st.session_state.target_names):
        status_text.text(f"ğŸ¯ XGBoost ëª¨ë¸ í•™ìŠµ ì¤‘: {target_name} ({idx+1}/{len(st.session_state.target_names)})")
        
        y_target = y[:, idx]
        
        scaler_y = StandardScaler()
        y_scaled = scaler_y.fit_transform(y_target.reshape(-1, 1)).ravel()
        st.session_state.scaler_y[target_name] = scaler_y
        
        # XGBoost Regressor ìƒì„±
        xgb_model = xgb.XGBRegressor(
            n_estimators=hyperparams['n_estimators'],
            max_depth=hyperparams['max_depth'],
            learning_rate=hyperparams['learning_rate'],
            subsample=hyperparams['subsample'],
            colsample_bytree=hyperparams['colsample_bytree'],
            min_child_weight=hyperparams['min_child_weight'],
            random_state=42,
            n_jobs=-1
        )
        
        xgb_model.fit(X_scaled, y_scaled)
        st.session_state.xgb_models[target_name] = xgb_model
        
        progress_bar.progress((idx + 1) / len(st.session_state.target_names))
    
    progress_bar.empty()
    status_text.empty()
    st.session_state.model_trained = True

def predict_time_series(input_values, time_points):
    """ì‹œê³„ì—´ ì˜ˆì¸¡ - XGBoost ì‚¬ìš©"""
    base_X = [input_values.get(feat, 0) for feat in st.session_state.feature_names]
    
    predictions_over_time = {target: [] for target in st.session_state.target_names}
    # XGBoostëŠ” ë¶ˆí™•ì‹¤ì„±ì„ ì§ì ‘ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì˜ˆì¸¡ê°’ë§Œ ë°˜í™˜
    uncertainties_over_time = {target: [] for target in st.session_state.target_names}
    
    for time_point in time_points:
        X_input = np.array([base_X + [time_point]])
        X_scaled = st.session_state.scaler_X.transform(X_input)
        
        for target_name in st.session_state.target_names:
            xgb_model = st.session_state.xgb_models[target_name]
            scaler_y = st.session_state.scaler_y[target_name]
            
            y_pred_scaled = xgb_model.predict(X_scaled)
            y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))[0, 0]
            
            # XGBoostëŠ” ë¶ˆí™•ì‹¤ì„±ì„ ì§ì ‘ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ê°„ë‹¨í•œ ì¶”ì •ê°’ ì‚¬ìš©
            # (ì‹¤ì œë¡œëŠ” SHAP ê°’ì´ë‚˜ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ë¶ˆí™•ì‹¤ì„±ì„ ì¶”ì •í•  ìˆ˜ ìˆìŒ)
            y_std = abs(y_pred) * 0.05  # ì˜ˆì¸¡ê°’ì˜ 5%ë¥¼ ë¶ˆí™•ì‹¤ì„±ìœ¼ë¡œ ì¶”ì •
            
            predictions_over_time[target_name].append(y_pred)
            uncertainties_over_time[target_name].append(y_std)
    
    return predictions_over_time, uncertainties_over_time

def smooth_curve(values, method='savgol', window_length=11, poly_order=3, spline_kind='cubic'):
    """
    ê³¡ì„  ìŠ¤ë¬´ë”© í•¨ìˆ˜ (ì‹œê°í™”ìš©)
    
    Args:
        values: ìŠ¤ë¬´ë”©í•  ê°’ë“¤ì˜ ë°°ì—´
        method: ìŠ¤ë¬´ë”© ë°©ë²• ('savgol', 'spline', 'moving_avg')
        window_length: Savitzky-Golay í•„í„°ì˜ ìœˆë„ìš° ê¸¸ì´ (í™€ìˆ˜ì—¬ì•¼ í•¨)
        poly_order: ë‹¤í•­ì‹ ì°¨ìˆ˜
        spline_kind: ìŠ¤í”Œë¼ì¸ ì¢…ë¥˜ ('linear', 'cubic', 'quadratic')
    
    Returns:
        ìŠ¤ë¬´ë”©ëœ ê°’ë“¤ì˜ ë°°ì—´
    """
    values = np.array(values)
    
    if len(values) < 3:
        return values
    
    if method == 'savgol':
        # Savitzky-Golay í•„í„°
        # window_lengthëŠ” í™€ìˆ˜ì—¬ì•¼ í•˜ê³ , ë°ì´í„° ê¸¸ì´ë³´ë‹¤ ì‘ì•„ì•¼ í•¨
        wl = min(window_length, len(values))
        if wl % 2 == 0:
            wl -= 1
        if wl < 3:
            wl = 3
        
        po = min(poly_order, wl - 1)
        if po < 1:
            po = 1
        
        try:
            smoothed = savgol_filter(values, wl, po)
            # ìŒìˆ˜ ê°’ ë°©ì§€ (ë¬¼ë¦¬ì  ì œì•½)
            smoothed = np.maximum(smoothed, 0)
            return smoothed
        except:
            return values
    
    elif method == 'spline':
        # ìŠ¤í”Œë¼ì¸ ë³´ê°„
        x_original = np.arange(len(values))
        x_smooth = np.linspace(0, len(values) - 1, len(values) * 2)
        
        try:
            f = interp1d(x_original, values, kind=spline_kind, bounds_error=False, fill_value='extrapolate')
            smoothed = f(x_smooth)
            # ì›ë˜ ê¸¸ì´ë¡œ ë‹¤ìš´ìƒ˜í”Œë§
            indices = np.linspace(0, len(smoothed) - 1, len(values), dtype=int)
            smoothed = smoothed[indices]
            smoothed = np.maximum(smoothed, 0)
            return smoothed
        except:
            return values
    
    elif method == 'moving_avg':
        # ì´ë™ í‰ê· 
        window = min(window_length, len(values))
        if window % 2 == 0:
            window -= 1
        if window < 3:
            window = 3
        
        # íŒ¨ë”© ì¶”ê°€ (ê²½ê³„ ì²˜ë¦¬)
        padded = np.pad(values, (window // 2, window // 2), mode='edge')
        smoothed = np.convolve(padded, np.ones(window) / window, mode='valid')
        smoothed = np.maximum(smoothed, 0)
        return smoothed
    
    else:
        return values

def check_physical_validity(predictions):
    """ë¬¼ë¦¬ì  ìœ íš¨ì„± ê²€ì‚¬"""
    warnings = []
    
    for key, values in predictions.items():
        if isinstance(values, list):
            if any(v < 0 for v in values):
                min_val = min(values)
                warnings.append(f"âš ï¸ {key}ì— ìŒìˆ˜ ê°’ ì¡´ì¬ (ìµœì†Œ: {min_val:.4e})")
        elif values < 0:
            warnings.append(f"âš ï¸ {key} ê°’ì´ ìŒìˆ˜ì…ë‹ˆë‹¤ ({values:.4e})")
    
    return warnings

# ==================== UI ====================

st.title("ğŸ§¬ ë¯¸ì„¸ìƒë¦¬ìœ ì²´ì¹© ì•½ë¬¼ ë™íƒœ ë¶„ì„ ì‹œìŠ¤í…œ")
st.markdown("### ë””ì§€í„¸ íŠ¸ìœˆ ì‹œë®¬ë ˆì´ì…˜ ë° XGBoost íšŒê·€ ëª¨ë¸ ê¸°ë°˜ ì˜ˆì¸¡")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ“ ë°ì´í„° ì—…ë¡œë“œ")
    
    uploaded_files = st.file_uploader(
        "ì—‘ì…€ ë˜ëŠ” CSV íŒŒì¼",
        type=['xlsx', 'xls', 'csv'],
        accept_multiple_files=True,
        help="sol765.xlsxì™€ Injection site results.xlsx ëª¨ë‘ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )
    
    st.markdown("---")
    st.info(f"â­ï¸ ì œì™¸ ì‹œíŠ¸: {', '.join(EXCLUDE_SHEETS)}")
    
    st.markdown("---")
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ UI
    st.header("âš™ï¸ XGBoost í•˜ì´í¼íŒŒë¼ë¯¸í„°")
    
    with st.expander("ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •", expanded=False):
        st.session_state.hyperparams['n_estimators'] = st.slider(
            "n_estimators (íŠ¸ë¦¬ ê°œìˆ˜)",
            min_value=50,
            max_value=500,
            value=st.session_state.hyperparams['n_estimators'],
            step=50,
            help="ë” ë§ì€ íŠ¸ë¦¬ëŠ” ë” ì •í™•í•˜ì§€ë§Œ í•™ìŠµ ì‹œê°„ì´ ê¸¸ì–´ì§‘ë‹ˆë‹¤"
        )
        
        st.session_state.hyperparams['max_depth'] = st.slider(
            "max_depth (íŠ¸ë¦¬ ê¹Šì´)",
            min_value=3,
            max_value=10,
            value=st.session_state.hyperparams['max_depth'],
            step=1,
            help="ê¹Šì€ íŠ¸ë¦¬ëŠ” ë³µì¡í•œ íŒ¨í„´ì„ í•™ìŠµí•˜ì§€ë§Œ ê³¼ì í•© ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤"
        )
        
        st.session_state.hyperparams['learning_rate'] = st.slider(
            "learning_rate (í•™ìŠµë¥ )",
            min_value=0.01,
            max_value=0.3,
            value=st.session_state.hyperparams['learning_rate'],
            step=0.01,
            help="ë‚®ì€ í•™ìŠµë¥ ì€ ë” ì•ˆì •ì ì´ì§€ë§Œ ë” ë§ì€ íŠ¸ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤"
        )
        
        st.session_state.hyperparams['subsample'] = st.slider(
            "subsample (ìƒ˜í”Œ ë¹„ìœ¨)",
            min_value=0.5,
            max_value=1.0,
            value=st.session_state.hyperparams['subsample'],
            step=0.1,
            help="ê° íŠ¸ë¦¬ì— ì‚¬ìš©í•  ìƒ˜í”Œ ë¹„ìœ¨ (ê³¼ì í•© ë°©ì§€)"
        )
        
        st.session_state.hyperparams['colsample_bytree'] = st.slider(
            "colsample_bytree (íŠ¹ì„± ìƒ˜í”Œ ë¹„ìœ¨)",
            min_value=0.5,
            max_value=1.0,
            value=st.session_state.hyperparams['colsample_bytree'],
            step=0.1,
            help="ê° íŠ¸ë¦¬ì— ì‚¬ìš©í•  íŠ¹ì„± ë¹„ìœ¨"
        )
        
        st.session_state.hyperparams['min_child_weight'] = st.slider(
            "min_child_weight (ìµœì†Œ ìì‹ ê°€ì¤‘ì¹˜)",
            min_value=1,
            max_value=10,
            value=st.session_state.hyperparams['min_child_weight'],
            step=1,
            help="ë¦¬í”„ ë…¸ë“œì˜ ìµœì†Œ ìƒ˜í”Œ ìˆ˜ (ê³¼ì í•© ë°©ì§€)"
        )
    
    st.markdown("---")
    
    if uploaded_files:
        if st.button("ğŸš€ ë°ì´í„° í•™ìŠµ ì‹œì‘", type="primary", use_container_width=True):
            with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                X, y = load_and_process_files(uploaded_files)
                
                if X is not None and y is not None:
                    st.markdown("---")
                    st.info(f"ğŸ“Š ì´ ìƒ˜í”Œ: {X.shape[0]}ê°œ")
                    st.info(f"ğŸ“¥ ì…ë ¥: ì•½ë¬¼ 5ê°œ + Time")
                    st.info(f"ğŸ“¤ íƒ€ê²Ÿ: {y.shape[1]}ê°œ")
                    
                    train_xgboost_models(X, y, st.session_state.hyperparams)
                    st.success("âœ…âœ… XGBoost ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
                    
                    if st.session_state.default_values:
                        st.markdown("---")
                        st.success("ğŸ¯ Case 1 ê¸°ë³¸ê°’:")
                        for feat in st.session_state.feature_names:
                            val = st.session_state.default_values.get(feat, 0)
                            st.text(f"{feat}: {val:.2e}")
                else:
                    st.error("âŒ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨")
    
    st.markdown("---")
    
    # ê·¸ë˜í”„ ìŠ¤ë¬´ë”© ì˜µì…˜ UI
    st.header("ğŸ“ˆ ê·¸ë˜í”„ ìŠ¤ë¬´ë”©")
    
    st.session_state.smoothing_params['enabled'] = st.checkbox(
        "ìŠ¤ë¬´ë”© í™œì„±í™”",
        value=st.session_state.smoothing_params['enabled'],
        help="ê·¸ë˜í”„ë¥¼ ë§¤ë„ëŸ½ê²Œ í‘œì‹œí•©ë‹ˆë‹¤ (ì›ë³¸ ì˜ˆì¸¡ê°’ì€ ë³€ê²½ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤)"
    )
    
    if st.session_state.smoothing_params['enabled']:
        st.session_state.smoothing_params['method'] = st.selectbox(
            "ìŠ¤ë¬´ë”© ë°©ë²•",
            ['savgol', 'spline', 'moving_avg'],
            index=['savgol', 'spline', 'moving_avg'].index(st.session_state.smoothing_params['method']),
            help="Savitzky-Golay: ë…¸ì´ì¦ˆ ì œê±°ì— íš¨ê³¼ì  | Spline: ë¶€ë“œëŸ¬ìš´ ê³¡ì„  | Moving Avg: ê°„ë‹¨í•œ í‰í™œí™”"
        )
        
        if st.session_state.smoothing_params['method'] == 'savgol':
            st.session_state.smoothing_params['window_length'] = st.slider(
                "ìœˆë„ìš° ê¸¸ì´ (í™€ìˆ˜)",
                min_value=5,
                max_value=51,
                value=st.session_state.smoothing_params['window_length'],
                step=2,
                help="ê°’ì´ í´ìˆ˜ë¡ ë” ë¶€ë“œëŸ½ì§€ë§Œ ì„¸ë¶€ íŠ¹ì§•ì´ ì‚¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
            )
            st.session_state.smoothing_params['poly_order'] = st.slider(
                "ë‹¤í•­ì‹ ì°¨ìˆ˜",
                min_value=1,
                max_value=5,
                value=st.session_state.smoothing_params['poly_order'],
                help="ìœˆë„ìš° ê¸¸ì´ë³´ë‹¤ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤"
            )
        
        elif st.session_state.smoothing_params['method'] == 'spline':
            st.session_state.smoothing_params['spline_kind'] = st.selectbox(
                "ìŠ¤í”Œë¼ì¸ ì¢…ë¥˜",
                ['linear', 'quadratic', 'cubic'],
                index=['linear', 'quadratic', 'cubic'].index(st.session_state.smoothing_params['spline_kind']),
                help="cubicì´ ê°€ì¥ ë¶€ë“œëŸ½ìŠµë‹ˆë‹¤"
            )
        
        elif st.session_state.smoothing_params['method'] == 'moving_avg':
            st.session_state.smoothing_params['window_length'] = st.slider(
                "ìœˆë„ìš° ê¸¸ì´ (í™€ìˆ˜)",
                min_value=3,
                max_value=21,
                value=st.session_state.smoothing_params['window_length'],
                step=2,
                help="í‰ê· ì„ ë‚¼ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜"
            )
    
    st.markdown("---")
    st.header("â„¹ï¸ ë°ì´í„° ìˆœì„œ")
    st.markdown("""
    **ì˜¬ë°”ë¥¸ íƒ€ê²Ÿ ìˆœì„œ:**
    1. Total mass
    2. Lymph
    3. Blood
    4. **Decay** â† 4ë²ˆì§¸!
    5. **ECM** â† 5ë²ˆì§¸!
    
    (ì´ì „ ë²„ì „ì€ ìˆœì„œê°€ ë°”ë€Œì–´ ìˆì—ˆìŒ)
    """)

# ë©”ì¸ ì˜ì—­
if st.session_state.model_trained:
    st.success("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ. ì‹œê³„ì—´ ì˜ˆì¸¡ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    st.header("ğŸ”® ì•½ë¬¼ ë™íƒœ ì˜ˆì¸¡")
    
    input_method = st.radio(
        "ì…ë ¥ ë°©ì‹",
        ["ê¸°ë³¸ê°’ ì‚¬ìš© (Case 1)", "ì§ì ‘ ì…ë ¥"],
        horizontal=True
    )
    
    input_values = {}
    
    if input_method == "ê¸°ë³¸ê°’ ì‚¬ìš© (Case 1)":
        if st.session_state.default_values:
            input_values = st.session_state.default_values.copy()
            st.info("ğŸ“‹ Case 1 ê¸°ë³¸ê°’ ì‚¬ìš©")
            
            cols = st.columns(5)
            for idx, feat in enumerate(st.session_state.feature_names):
                with cols[idx]:
                    value = input_values.get(feat, 0.0)
                    st.metric(feat, f"{value:.2e}")
        else:
            st.warning("âš ï¸ Case 1 íŒŒì¼ ì—†ìŒ. ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.")
            input_method = "ì§ì ‘ ì…ë ¥"
    
    if input_method == "ì§ì ‘ ì…ë ¥":
        st.markdown("**ì…ë ¥ ë³€ìˆ˜ë¥¼ ì§ì ‘ ì…ë ¥í•´ì£¼ì„¸ìš”:**")
        
        cols = st.columns(5)
        for idx, feat in enumerate(st.session_state.feature_names):
            with cols[idx]:
                default_val = 0.0
                if st.session_state.default_values:
                    default_val = st.session_state.default_values.get(feat, 0.0)
                
                input_values[feat] = st.number_input(
                    feat,
                    value=float(default_val),
                    format="%.2e",
                    key=f"input_{feat}"
                )
    
    num_points = st.slider("ì‹œê³„ì—´ ì˜ˆì¸¡ í¬ì¸íŠ¸ ìˆ˜", min_value=50, max_value=200, value=100, step=10)
    
    if st.button("ğŸ¯ ì˜ˆì¸¡ ì‹¤í–‰ (0-72ì‹œê°„)", type="primary", use_container_width=True):
        with st.spinner("0~72ì‹œê°„ ì‹œê³„ì—´ ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘..."):
            time_points = np.linspace(0, 72, num_points)
            predictions, uncertainties = predict_time_series(input_values, time_points)
            
            validity_warnings = check_physical_validity(predictions)
            for warning in validity_warnings:
                st.warning(warning)
            
            st.markdown("---")
            st.header("ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼")
            
            st.markdown("### ğŸ“ˆ ì‹œê°„ì— ë”°ë¥¸ ì•½ë¬¼ ë™íƒœ ë³€í™” (0-72ì‹œê°„)")
            
            fig, ax = plt.subplots(figsize=(15, 8))
            
            # ğŸ”¥ ì˜¬ë°”ë¥¸ ìƒ‰ìƒ ë§¤í•‘ (Decayê°€ íŒŒë‘, ECMì´ ì£¼í™©)
            colors = {
                'Total mass': '#000000',
                'Lymph': '#00FF00',
                'Blood': '#FF0000',
                'Decay': '#0000FF',  # Decay = íŒŒë‘
                'ECM': '#FFA500'     # ECM = ì£¼í™©
            }
            
            for target_name in st.session_state.target_names:
                color = colors.get(target_name, '#888888')
                pred_values = predictions[target_name]
                uncert_values = uncertainties[target_name]
                
                # ìŠ¤ë¬´ë”© ì ìš© (ì‹œê°í™”ìš©ë§Œ, ì›ë³¸ ê°’ì€ ìœ ì§€)
                if st.session_state.smoothing_params['enabled']:
                    smoothed_values = smooth_curve(
                        pred_values,
                        method=st.session_state.smoothing_params['method'],
                        window_length=st.session_state.smoothing_params['window_length'],
                        poly_order=st.session_state.smoothing_params.get('poly_order', 3),
                        spline_kind=st.session_state.smoothing_params.get('spline_kind', 'cubic')
                    )
                    # ê·¸ë˜í”„ì—ëŠ” ìŠ¤ë¬´ë”©ëœ ê°’ ì‚¬ìš©
                    plot_values = smoothed_values
                else:
                    # ìŠ¤ë¬´ë”© ë¹„í™œì„±í™” ì‹œ ì›ë³¸ ê°’ ì‚¬ìš©
                    plot_values = pred_values
                
                ax.plot(time_points, plot_values, color=color, 
                       linewidth=2.5, label=target_name)
                
                # ë¶ˆí™•ì‹¤ì„± ì˜ì—­ì€ ì›ë³¸ ì˜ˆì¸¡ê°’ ê¸°ì¤€ìœ¼ë¡œ í‘œì‹œ
                pred_array = np.array(pred_values)
                uncert_array = np.array(uncert_values)
                ax.fill_between(time_points,
                               pred_array - 1.96 * uncert_array,
                               pred_array + 1.96 * uncert_array,
                               color=color, alpha=0.1)
            
            ax.set_xlabel('Time (h)', fontsize=14, fontweight='bold')
            ax.set_ylabel('%Mass (m/mâ‚€)', fontsize=14, fontweight='bold')
            ax.set_title('Representative', fontsize=16, fontweight='bold', style='italic')
            ax.legend(loc='center right', fontsize=12, framealpha=0.9)
            ax.grid(True, alpha=0.3, linestyle='--')
            ax.set_xlim(0, 72)
            ax.set_ylim(0, 105)
            
            plt.tight_layout()
            st.pyplot(fig)
            
            # ì£¼ìš” ì‹œê°„ëŒ€
            st.markdown("---")
            st.markdown("### ğŸ“‹ ì£¼ìš” ì‹œê°„ëŒ€ ì˜ˆì¸¡ê°’")
            
            key_times = [0, 6, 12, 24, 48, 72]
            key_indices = [np.argmin(np.abs(time_points - t)) for t in key_times]
            
            table_data = {'Time (h)': [time_points[i] for i in key_indices]}
            for target_name in st.session_state.target_names:
                table_data[target_name] = [f"{predictions[target_name][i]:.2f}" 
                                          for i in key_indices]
            
            df_display = pd.DataFrame(table_data)
            st.dataframe(df_display, use_container_width=True)
            
            # CSV ë‹¤ìš´ë¡œë“œ
            st.markdown("---")
            full_data = {'Time (h)': time_points}
            for target_name in st.session_state.target_names:
                full_data[target_name] = predictions[target_name]
                full_data[f'{target_name}_uncertainty'] = uncertainties[target_name]
            
            df_full = pd.DataFrame(full_data)
            csv = df_full.to_csv(index=False)
            
            st.download_button(
                label="ğŸ“¥ ì „ì²´ ì˜ˆì¸¡ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name="prediction_timeseries.csv",
                mime="text/csv",
                use_container_width=True
            )
            
            # ì…ë ¥ê°’
            st.markdown("---")
            st.markdown("### ğŸ”§ ì‚¬ìš©ëœ ì…ë ¥ ë³€ìˆ˜")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**ì•½ë¬¼ íŒŒë¼ë¯¸í„°**")
                input_df = pd.DataFrame({
                    'ë³€ìˆ˜ëª…': list(input_values.keys()),
                    'ì…ë ¥ê°’': [f"{v:.6e}" for v in input_values.values()]
                })
                st.dataframe(input_df, use_container_width=True)
            
            with col2:
                st.markdown("**ì˜ˆì¸¡ ì„¤ì •**")
                st.text(f"ì‹œê°„ ë²”ìœ„: 0-72 ì‹œê°„")
                st.text(f"ì˜ˆì¸¡ í¬ì¸íŠ¸: {num_points}ê°œ")
                st.text(f"ê°„ê²©: {72/num_points:.3f} ì‹œê°„")

else:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê³  í•™ìŠµí•˜ì„¸ìš”")
    
    st.markdown("---")
    st.header("ğŸ“– ì‚¬ìš© ë°©ë²•")
    
    with st.expander("ğŸ”¥ XGBoost ëª¨ë¸ ì •ë³´", expanded=True):
        st.markdown("""
        ### ëª¨ë¸ íŠ¹ì§•
        
        **1. XGBoost íšŒê·€ ëª¨ë¸**
        - Gaussian Process ëŒ€ì‹  XGBoost ì‚¬ìš©
        - ê° íƒ€ê²Ÿ ë³€ìˆ˜ë³„ ë…ë¦½ì ì¸ ëª¨ë¸ í•™ìŠµ
        - ë” ë¹ ë¥¸ í•™ìŠµ ë° ì˜ˆì¸¡ ì†ë„
        
        **2. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**
        - n_estimators: íŠ¸ë¦¬ ê°œìˆ˜ ì¡°ì •
        - max_depth: íŠ¸ë¦¬ ê¹Šì´ ì¡°ì •
        - learning_rate: í•™ìŠµë¥  ì¡°ì •
        - subsample, colsample_bytree: ê³¼ì í•© ë°©ì§€
        
        **3. íƒ€ê²Ÿ ë³€ìˆ˜ ìˆœì„œ**
        - Total mass â†’ Lymph â†’ Blood â†’ **Decay** â†’ **ECM**
        
        **4. ìƒ‰ìƒ ë§¤í•‘**
        - Decay = íŒŒë‘
        - ECM = ì£¼í™©
        """)
    
    with st.expander("ğŸ’¡ ì‚¬ìš© íŒ"):
        st.markdown("""
        1. ë‘ íŒŒì¼ ëª¨ë‘ ì—…ë¡œë“œ
        2. "í•™ìŠµ ì‹œì‘" í´ë¦­
        3. ì…ë ¥ ë³€ìˆ˜ ì„¤ì •
        4. "ì˜ˆì¸¡ ì‹¤í–‰"
        5. ê·¸ë˜í”„ê°€ ë¶€ë“œëŸ¬ìš´ ê³¡ì„ ìœ¼ë¡œ ë‚˜ì™€ì•¼ ì •ìƒ
        """)

st.markdown("---")
st.caption("ğŸ§¬ ë¯¸ì„¸ìƒë¦¬ìœ ì²´ì¹© ë””ì§€í„¸ íŠ¸ìœˆ ì‹œë®¬ë ˆì´ì…˜ | XGBoost íšŒê·€ ëª¨ë¸")
